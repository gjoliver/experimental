trial_id,episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,num_healthy_workers,timesteps_total,timesteps_this_iter,agent_timesteps_total,done,episodes_total,training_iteration,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,time_since_restore,timesteps_since_restore,iterations_since_restore,experiment_tag,hist_stats.episode_reward,hist_stats.episode_lengths,timers.load_time_ms,timers.load_throughput,timers.learn_time_ms,timers.learn_throughput,info.num_steps_trained,info.num_steps_trained_this_iter,info.num_agent_steps_trained,info.num_steps_sampled,info.last_target_update_ts,evaluation.episode_reward_max,evaluation.episode_reward_min,evaluation.episode_reward_mean,evaluation.episode_len_mean,evaluation.episodes_this_iter,evaluation.timesteps_this_iter,config.num_workers,config.num_envs_per_worker,config.create_env_on_driver,config.rollout_fragment_length,config.batch_mode,config.gamma,config.lr,config.train_batch_size,config.horizon,config.soft_horizon,config.no_done_at_end,config.env,config.observation_space,config.action_space,config.remote_worker_envs,config.remote_env_batch_wait_ms,config.env_task_fn,config.render_env,config.record_env,config.clip_rewards,config.normalize_actions,config.clip_actions,config.preprocessor_pref,config.log_level,config.callbacks,config.ignore_worker_failures,config.log_sys_usage,config.fake_sampler,config.framework,config.eager_tracing,config.eager_max_retraces,config.explore,config.evaluation_interval,config.evaluation_duration,config.evaluation_duration_unit,config.evaluation_parallel_to_training,config.in_evaluation,config.evaluation_num_workers,config.custom_eval_function,config.always_attach_evaluation_results,config.sample_async,config.sample_collector,config.observation_filter,config.synchronize_filters,config.compress_observations,config.metrics_episode_collection_timeout_s,config.metrics_num_episodes_for_smoothing,config.min_time_s_per_reporting,config.min_train_timesteps_per_reporting,config.min_sample_timesteps_per_reporting,config.seed,config.num_gpus,config._fake_gpus,config.num_cpus_per_worker,config.num_gpus_per_worker,config.num_cpus_for_driver,config.placement_strategy,config.input,config.actions_in_input_normalized,config.input_evaluation,config.postprocess_inputs,config.shuffle_buffer_size,config.output,config.output_compress_columns,config.output_max_file_size,config.logger_config,config._tf_policy_handles_more_than_one_loss,config._disable_preprocessor_api,config._disable_action_flattening,config._disable_execution_plan_api,config.simple_optimizer,config.monitor,config.evaluation_num_episodes,config.metrics_smoothing_episodes,config.timesteps_per_iteration,config.min_iter_time_s,config.collect_metrics_timeout,config.twin_q,config.use_state_preprocessor,config.tau,config.initial_alpha,config.target_entropy,config.n_step,config.buffer_size,config.store_buffer_in_checkpoints,config.prioritized_replay,config.prioritized_replay_alpha,config.prioritized_replay_beta,config.prioritized_replay_eps,config.prioritized_replay_beta_annealing_timesteps,config.final_prioritized_replay_beta,config.training_intensity,config.grad_clip,config.learning_starts,config.target_network_update_freq,config.worker_side_prioritization,config._deterministic_loss,config._use_beta_distribution,config.bc_iters,config.temperature,config.num_actions,config.lagrangian,config.lagrangian_thresh,config.min_q_weight,perf.cpu_util_percent,perf.ram_util_percent,evaluation.hist_stats.episode_reward,evaluation.hist_stats.episode_lengths,evaluation.sampler_perf.mean_raw_obs_processing_ms,evaluation.sampler_perf.mean_inference_ms,evaluation.sampler_perf.mean_action_processing_ms,evaluation.sampler_perf.mean_env_wait_ms,evaluation.sampler_perf.mean_env_render_ms,config.model._use_default_native_models,config.model._disable_preprocessor_api,config.model.fcnet_hiddens,config.model.fcnet_activation,config.model.conv_filters,config.model.conv_activation,config.model.post_fcnet_hiddens,config.model.post_fcnet_activation,config.model.free_log_std,config.model.no_final_linear,config.model.vf_share_layers,config.model.use_lstm,config.model.max_seq_len,config.model.lstm_cell_size,config.model.lstm_use_prev_action,config.model.lstm_use_prev_reward,config.model._time_major,config.model.use_attention,config.model.attention_num_transformer_units,config.model.attention_dim,config.model.attention_num_heads,config.model.attention_head_dim,config.model.attention_memory_inference,config.model.attention_memory_training,config.model.attention_position_wise_mlp_dim,config.model.attention_init_gru_gate_bias,config.model.attention_use_n_prev_actions,config.model.attention_use_n_prev_rewards,config.model.framestack,config.model.dim,config.model.grayscale,config.model.zero_mean,config.model.custom_model,config.model.custom_action_dist,config.model.custom_preprocessor,config.model.lstm_use_prev_action_reward,config.exploration_config.type,config.evaluation_config.num_workers,config.evaluation_config.num_envs_per_worker,config.evaluation_config.create_env_on_driver,config.evaluation_config.rollout_fragment_length,config.evaluation_config.batch_mode,config.evaluation_config.gamma,config.evaluation_config.lr,config.evaluation_config.train_batch_size,config.evaluation_config.horizon,config.evaluation_config.soft_horizon,config.evaluation_config.no_done_at_end,config.evaluation_config.env,config.evaluation_config.observation_space,config.evaluation_config.action_space,config.evaluation_config.remote_worker_envs,config.evaluation_config.remote_env_batch_wait_ms,config.evaluation_config.env_task_fn,config.evaluation_config.render_env,config.evaluation_config.record_env,config.evaluation_config.clip_rewards,config.evaluation_config.normalize_actions,config.evaluation_config.clip_actions,config.evaluation_config.preprocessor_pref,config.evaluation_config.log_level,config.evaluation_config.callbacks,config.evaluation_config.ignore_worker_failures,config.evaluation_config.log_sys_usage,config.evaluation_config.fake_sampler,config.evaluation_config.framework,config.evaluation_config.eager_tracing,config.evaluation_config.eager_max_retraces,config.evaluation_config.explore,config.evaluation_config.evaluation_interval,config.evaluation_config.evaluation_duration,config.evaluation_config.evaluation_duration_unit,config.evaluation_config.evaluation_parallel_to_training,config.evaluation_config.in_evaluation,config.evaluation_config.evaluation_num_workers,config.evaluation_config.custom_eval_function,config.evaluation_config.always_attach_evaluation_results,config.evaluation_config.sample_async,config.evaluation_config.sample_collector,config.evaluation_config.observation_filter,config.evaluation_config.synchronize_filters,config.evaluation_config.compress_observations,config.evaluation_config.metrics_episode_collection_timeout_s,config.evaluation_config.metrics_num_episodes_for_smoothing,config.evaluation_config.min_time_s_per_reporting,config.evaluation_config.min_train_timesteps_per_reporting,config.evaluation_config.min_sample_timesteps_per_reporting,config.evaluation_config.seed,config.evaluation_config.num_gpus,config.evaluation_config._fake_gpus,config.evaluation_config.num_cpus_per_worker,config.evaluation_config.num_gpus_per_worker,config.evaluation_config.num_cpus_for_driver,config.evaluation_config.placement_strategy,config.evaluation_config.input,config.evaluation_config.actions_in_input_normalized,config.evaluation_config.input_evaluation,config.evaluation_config.postprocess_inputs,config.evaluation_config.shuffle_buffer_size,config.evaluation_config.output,config.evaluation_config.output_compress_columns,config.evaluation_config.output_max_file_size,config.evaluation_config.logger_config,config.evaluation_config._tf_policy_handles_more_than_one_loss,config.evaluation_config._disable_preprocessor_api,config.evaluation_config._disable_action_flattening,config.evaluation_config._disable_execution_plan_api,config.evaluation_config.simple_optimizer,config.evaluation_config.monitor,config.evaluation_config.evaluation_num_episodes,config.evaluation_config.metrics_smoothing_episodes,config.evaluation_config.timesteps_per_iteration,config.evaluation_config.min_iter_time_s,config.evaluation_config.collect_metrics_timeout,config.evaluation_config.twin_q,config.evaluation_config.use_state_preprocessor,config.evaluation_config.tau,config.evaluation_config.initial_alpha,config.evaluation_config.target_entropy,config.evaluation_config.n_step,config.evaluation_config.buffer_size,config.evaluation_config.store_buffer_in_checkpoints,config.evaluation_config.prioritized_replay,config.evaluation_config.prioritized_replay_alpha,config.evaluation_config.prioritized_replay_beta,config.evaluation_config.prioritized_replay_eps,config.evaluation_config.prioritized_replay_beta_annealing_timesteps,config.evaluation_config.final_prioritized_replay_beta,config.evaluation_config.training_intensity,config.evaluation_config.grad_clip,config.evaluation_config.learning_starts,config.evaluation_config.target_network_update_freq,config.evaluation_config.worker_side_prioritization,config.evaluation_config._deterministic_loss,config.evaluation_config._use_beta_distribution,config.evaluation_config.bc_iters,config.evaluation_config.temperature,config.evaluation_config.num_actions,config.evaluation_config.lagrangian,config.evaluation_config.lagrangian_thresh,config.evaluation_config.min_q_weight,config.tf_session_args.intra_op_parallelism_threads,config.tf_session_args.inter_op_parallelism_threads,config.tf_session_args.log_device_placement,config.tf_session_args.allow_soft_placement,config.local_tf_session_args.intra_op_parallelism_threads,config.local_tf_session_args.inter_op_parallelism_threads,config.multiagent.policy_map_capacity,config.multiagent.policy_map_cache,config.multiagent.policy_mapping_fn,config.multiagent.policies_to_train,config.multiagent.observation_fn,config.multiagent.replay_mode,config.multiagent.count_steps_by,config.Q_model.fcnet_hiddens,config.Q_model.fcnet_activation,config.Q_model.post_fcnet_hiddens,config.Q_model.post_fcnet_activation,config.Q_model.custom_model,config.policy_model.fcnet_hiddens,config.policy_model.fcnet_activation,config.policy_model.post_fcnet_hiddens,config.policy_model.post_fcnet_activation,config.policy_model.custom_model,config.replay_buffer_config.type,config.replay_buffer_config.capacity,config.optimization.actor_learning_rate,config.optimization.critic_learning_rate,config.optimization.entropy_learning_rate,config.evaluation_config.model._use_default_native_models,config.evaluation_config.model._disable_preprocessor_api,config.evaluation_config.model.fcnet_hiddens,config.evaluation_config.model.fcnet_activation,config.evaluation_config.model.conv_filters,config.evaluation_config.model.conv_activation,config.evaluation_config.model.post_fcnet_hiddens,config.evaluation_config.model.post_fcnet_activation,config.evaluation_config.model.free_log_std,config.evaluation_config.model.no_final_linear,config.evaluation_config.model.vf_share_layers,config.evaluation_config.model.use_lstm,config.evaluation_config.model.max_seq_len,config.evaluation_config.model.lstm_cell_size,config.evaluation_config.model.lstm_use_prev_action,config.evaluation_config.model.lstm_use_prev_reward,config.evaluation_config.model._time_major,config.evaluation_config.model.use_attention,config.evaluation_config.model.attention_num_transformer_units,config.evaluation_config.model.attention_dim,config.evaluation_config.model.attention_num_heads,config.evaluation_config.model.attention_head_dim,config.evaluation_config.model.attention_memory_inference,config.evaluation_config.model.attention_memory_training,config.evaluation_config.model.attention_position_wise_mlp_dim,config.evaluation_config.model.attention_init_gru_gate_bias,config.evaluation_config.model.attention_use_n_prev_actions,config.evaluation_config.model.attention_use_n_prev_rewards,config.evaluation_config.model.framestack,config.evaluation_config.model.dim,config.evaluation_config.model.grayscale,config.evaluation_config.model.zero_mean,config.evaluation_config.model.custom_model,config.evaluation_config.model.custom_action_dist,config.evaluation_config.model.custom_preprocessor,config.evaluation_config.model.lstm_use_prev_action_reward,config.evaluation_config.exploration_config.type,config.evaluation_config.evaluation_config.input,config.evaluation_config.tf_session_args.intra_op_parallelism_threads,config.evaluation_config.tf_session_args.inter_op_parallelism_threads,config.evaluation_config.tf_session_args.log_device_placement,config.evaluation_config.tf_session_args.allow_soft_placement,config.evaluation_config.local_tf_session_args.intra_op_parallelism_threads,config.evaluation_config.local_tf_session_args.inter_op_parallelism_threads,config.evaluation_config.multiagent.policy_map_capacity,config.evaluation_config.multiagent.policy_map_cache,config.evaluation_config.multiagent.policy_mapping_fn,config.evaluation_config.multiagent.policies_to_train,config.evaluation_config.multiagent.observation_fn,config.evaluation_config.multiagent.replay_mode,config.evaluation_config.multiagent.count_steps_by,config.evaluation_config.Q_model.fcnet_hiddens,config.evaluation_config.Q_model.fcnet_activation,config.evaluation_config.Q_model.post_fcnet_hiddens,config.evaluation_config.Q_model.post_fcnet_activation,config.evaluation_config.Q_model.custom_model,config.evaluation_config.policy_model.fcnet_hiddens,config.evaluation_config.policy_model.fcnet_activation,config.evaluation_config.policy_model.post_fcnet_hiddens,config.evaluation_config.policy_model.post_fcnet_activation,config.evaluation_config.policy_model.custom_model,config.evaluation_config.replay_buffer_config.type,config.evaluation_config.replay_buffer_config.capacity,config.evaluation_config.optimization.actor_learning_rate,config.evaluation_config.optimization.critic_learning_rate,config.evaluation_config.optimization.entropy_learning_rate,config.tf_session_args.gpu_options.allow_growth,config.tf_session_args.device_count.CPU,config.multiagent.policies.default_policy,info.learner.default_policy.learner_stats.mean_td_error,info.learner.default_policy.learner_stats.actor_loss,info.learner.default_policy.learner_stats.critic_loss,info.learner.default_policy.learner_stats.alpha_loss,info.learner.default_policy.learner_stats.alpha_value,info.learner.default_policy.learner_stats.target_entropy,info.learner.default_policy.learner_stats.mean_q,info.learner.default_policy.learner_stats.max_q,info.learner.default_policy.learner_stats.min_q,info.learner.default_policy.learner_stats.cql_loss,config.evaluation_config.tf_session_args.gpu_options.allow_growth,config.evaluation_config.tf_session_args.device_count.CPU,config.evaluation_config.multiagent.policies.default_policy
4d5fa_00000,,,,,0,0,48128,256,0,False,0,14,4a0cc928a2124ea29c077b8433cb2df7,2022-01-10_10-39-04,1641839944,1.1456611156463623,105.16610336303711,89861,Juns-MacBook-Pro.local,127.0.0.1,105.16610336303711,3584,14,0,[],[],0.105,2446438.423,64.178,3988.912,48128,256,48128,0,0,-1035.0624514860237,-1471.5688083910757,-1294.132174534819,1000.0,10,10000,0,1,False,3,truncate_episodes,0.99,0.0001,256,1000,False,False,HalfCheetahBulletEnv-v0,,,False,0,,False,False,,True,False,deepmind,WARN,<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>,False,True,False,tf,False,20,True,5,10,episodes,False,False,0,,True,False,<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,NoFilter,True,False,180,5,1,,1000,,0,False,1,0,1,PACK,['~/halfcheetah_expert_sac.zip'],True,[],False,0,,"['obs', 'new_obs']",67108864,,False,False,False,False,False,-1,-1,5,1000,1,-1,True,-1,0.005,1.0,auto,3,-1,False,False,0.6,0.4,1e-06,20000,0.4,,,256,0,False,False,False,20000,1.0,10,False,5.0,5.0,34.3,74.5,"[-1471.5688083910757, -1262.6328312165658, -1148.624033168974, -1305.3726776426684, -1373.937790734734, -1397.5641497135987, -1035.0624514860237, -1461.76791563427, -1142.3663899417759, -1342.424697418502]","[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]",0.05454759849058939,3.891561360461945,0.08051324251872125,0.4883832761296201,0.0,False,False,"[256, 256]",tanh,,relu,[],relu,False,False,True,False,20,256,False,False,False,False,1,64,1,32,50,50,32,2.0,0,0,True,84,False,True,,,,-1,StochasticSampling,0,1,False,1,complete_episodes,0.99,0.0001,256,1000,False,False,HalfCheetahBulletEnv-v0,,,False,0,,False,False,,True,False,deepmind,WARN,<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>,False,True,False,tf,False,20,True,5,10,episodes,False,True,0,,True,False,<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,NoFilter,True,False,180,5,1,,1000,,0,False,1,0,1,PACK,sampler,True,[],False,0,,"['obs', 'new_obs']",67108864,,False,False,False,False,False,-1,-1,5,1000,1,-1,True,-1,0.005,1.0,auto,3,-1,False,False,0.6,0.4,1e-06,20000,0.4,,,256,0,False,False,False,20000,1.0,10,False,5.0,5.0,2,2,False,True,8,8,100,,,,,independent,env_steps,"[256, 256, 256]",relu,[],,,"[256, 256, 256]",relu,[],,,MultiAgentReplayBuffer,1000000,0.0001,0.0003,0.0001,False,False,"[256, 256]",tanh,,relu,[],relu,False,False,True,False,20,256,False,False,False,False,1,64,1,32,50,50,32,2.0,0,0,True,84,False,True,,,,-1,StochasticSampling,sampler,2,2,False,True,8,8,100,,,,,independent,env_steps,"[256, 256, 256]",relu,[],,,"[256, 256, 256]",relu,[],,,MultiAgentReplayBuffer,1000000,0.0001,0.0003,0.0001,True,1,"PolicySpec(policy_class=None, observation_space=None, action_space=None, config={})",1.2682686,-1.4328024,11.093821,-0.14890721,0.9822835,-6.0,0.6630716,4.0567355,-7.7387776,8.425999,True,1,"PolicySpec(policy_class=None, observation_space=None, action_space=None, config={})"
